{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00ff8c27-c4af-4ab4-97ab-e7330a2af7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29e8e777-cdde-489c-9bc7-6d839483b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../datasets/export-lindat/lindat-20251031_json/metadata_20251031.json\", \"r\") as f:\n",
    "    meta = pd.DataFrame(json.load(f)).set_index(\"screening_id\")\n",
    "\n",
    "target_map = {0: 0, 2: 1, 3: 1}  # map targets: 0 -> 0 and (2, 3) -> 1\n",
    "raget_key = \"kobar_kategorizace_definitivni\"\n",
    "targets = meta.loc[meta[raget_key].isin(target_map), raget_key].map(target_map).sort_index()\n",
    "\n",
    "with open(\"../../datasets/export-lindat/lindat-20251031_json/expert_features_zipformer_lm-extra06.json\", \"r\") as f:\n",
    "    features = pd.DataFrame(json.load(f)).set_index(\"screening_id\")\n",
    "    features = features.loc[features.index.intersection(targets.index)].sort_index()\n",
    "\n",
    "with open(\"../../datasets/export-lindat/lindat-20251031_json/train_20251031.json\", \"r\") as f:\n",
    "    train_ids = json.load(f)\n",
    "with open(\"../../datasets/export-lindat/lindat-20251031_json/test_20251031.json\", \"r\") as f:\n",
    "    test_ids = json.load(f)\n",
    "\n",
    "X_train = features.loc[features.index.isin(train_ids)]\n",
    "y_train = targets.loc[targets.index.isin(train_ids)]\n",
    "\n",
    "X_test = features.loc[features.index.isin(test_ids)]\n",
    "y_test = targets.loc[targets.index.isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4f65f3f-6a2d-4f60-aa21-c8379eb6d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(random_state=42, max_iter=1000, solver=\"liblinear\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80bc570c-65b4-48d6-a895-db679b703056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        42\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.35      0.50      0.41        60\n",
      "weighted avg       0.49      0.70      0.58        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 01\n",
    "features = [\"expertFeatures_1_task1 Correctly repeated numbers\"]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb210e4-8267-41fe-ba7d-a1d91dd9b8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        42\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.35      0.50      0.41        60\n",
      "weighted avg       0.49      0.70      0.58        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 02\n",
    "features = [\"expertFeatures_2_task2 Correctly repeated characters\"]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cb0227e-363e-4d65-bf27-e9895b2827d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        42\n",
      "           1       0.62      0.44      0.52        18\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.70      0.66      0.67        60\n",
      "weighted avg       0.74      0.75      0.74        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 03\n",
    "features = [\n",
    "    \"expertFeatures_3_task3 Character match ratio\",\n",
    "    \"expertFeatures_4_task3 Correctly repeated words\"\n",
    "]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46f79416-3087-467f-83dd-e89b3c908fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        42\n",
      "           1       0.57      0.44      0.50        18\n",
      "\n",
      "    accuracy                           0.73        60\n",
      "   macro avg       0.68      0.65      0.66        60\n",
      "weighted avg       0.72      0.73      0.72        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 04 - morphological analysis\n",
    "features = [\n",
    "    \"expertFeatures_5_task4 Sentence count\",\n",
    "    \"expertFeatures_6_task4 First person verb proportion\",\n",
    "    \"expertFeatures_7_task4 Meaningful words ratio\",\n",
    "    \"expertFeatures_8_task4 Pronoun to noun ratio\",\n",
    "    \"expertFeatures_9_task4 Count of repeated meaningful words\",\n",
    "    \"expertFeatures_10_task4 Unique words to total words\",\n",
    "]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43e71d6a-c8e4-4ab5-8886-457e215a49da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        42\n",
      "           1       0.59      0.56      0.57        18\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.70      0.69      0.70        60\n",
      "weighted avg       0.75      0.75      0.75        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 04 - semantic analysis\n",
    "features = [\n",
    "    \"expertFeatures_11_task4 Named object count\",\n",
    "    \"expertFeatures_12_task4 Described object relation count\",\n",
    "    \"expertFeatures_13_task4 Distinct topic count\",\n",
    "    \"expertFeatures_14_task4 Description trajectory length\",\n",
    "    \"expertFeatures_15_task4 Objects in water count\",\n",
    "    \"expertFeatures_16_task4 Objects in sky count\",\n",
    "    \"expertFeatures_17_task4 Objects on land count\",\n",
    "    \"expertFeatures_18_task4 Explicit child danger mentioned\",\n",
    "    \"expertFeatures_19_task4 Explicit animal danger mentioned\",\n",
    "]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b01f124-7b8e-4457-bd58-313e78158397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90        42\n",
      "           1       0.85      0.61      0.71        18\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.85      0.78      0.80        60\n",
      "weighted avg       0.85      0.85      0.84        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 05\n",
    "features = [\n",
    "    \"expertFeatures_20_task5 Total recalled words count\",\n",
    "    \"expertFeatures_21_task5 Distinct objects recalled count\",\n",
    "    \"expertFeatures_22_task5 Repeated recalled words count\",\n",
    "]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4061b195-2b15-41c1-b148-7f7bc0876f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84        42\n",
      "           1       0.67      0.44      0.53        18\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.73      0.67      0.69        60\n",
      "weighted avg       0.75      0.77      0.75        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 06\n",
    "features = [\n",
    "    \"expertFeatures_23_task6 Correctly named pictures count\",\n",
    "    \"expertFeatures_24_task6 Total naming reaction time\",\n",
    "]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c278c319-9968-47bf-9068-cb8d6e234d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        42\n",
      "           1       0.76      0.72      0.74        18\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.82      0.81      0.82        60\n",
      "weighted avg       0.85      0.85      0.85        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 07\n",
    "features = [\"expertFeatures_25_task7 Correctly recalled pictures count\"]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "447e0ab3-2ddf-4b2f-bdd1-1acb5ff17611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92        42\n",
      "           1       0.79      0.83      0.81        18\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.86      0.87      0.86        60\n",
      "weighted avg       0.89      0.88      0.88        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 08\n",
    "features = [\n",
    "    \"expertFeatures_26_task8 Total word count\",\n",
    "    \"expertFeatures_27_task8 Animal word count\",\n",
    "    \"expertFeatures_28_task8 Repeated animals count\",\n",
    "]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c9aa74e-2441-4400-a1cc-4b4df0826994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        42\n",
      "           1       0.76      0.72      0.74        18\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.82      0.81      0.82        60\n",
      "weighted avg       0.85      0.85      0.85        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 09\n",
    "features = [\n",
    "    \"expertFeatures_29_task9 Percentage of repeated-recalled sentence characters\",\n",
    "    \"expertFeatures_30_task9 Correct recalled sentence words count\",\n",
    "]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9adcf366-ff4a-4353-a33d-f508bafcc25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80        42\n",
      "           1       0.25      0.06      0.09        18\n",
      "\n",
      "    accuracy                           0.67        60\n",
      "   macro avg       0.47      0.49      0.44        60\n",
      "weighted avg       0.56      0.67      0.58        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 10\n",
    "features = [\"expertFeatures_31_task10 Word similarity score\"]\n",
    "\n",
    "X_train_task = X_train[features]\n",
    "y_train_task = y_train.loc[y_train.index.intersection(X_train_task.index)]\n",
    "\n",
    "X_test_task = X_test[features]\n",
    "y_test_task = y_test.loc[y_test.index.intersection(X_test_task.index)]\n",
    "\n",
    "model.fit(X_train_task, y_train_task)\n",
    "predicted = model.predict(X_test_task)\n",
    "report = classification_report(y_test_task, predicted, zero_division=0.0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3bbcb-41c0-46db-a79d-a21b7e2aaba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
